{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabetical_critics_URL = ['https://www.rottentomatoes.com/critics/authors?letter=' + i for i in string.ascii_lowercase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we scrap all reviewers name and URL \n",
    "\n",
    "all_critics = {'critic_name':[], 'critic_URL':[]}\n",
    "headers = {'User-Agent': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
    "for query in alphabetical_critics_URL:\n",
    "    r = requests.get(query, headers=headers)\n",
    "    if r.status_code != 200:\n",
    "        print('problem while attempting to scrap :', query)\n",
    "    else:\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        for critic in soup.select('.critic-authors__name'):\n",
    "            all_critics['critic_name'].append(critic.get_text())\n",
    "            all_critics['critic_URL'].append('https://www.rottentomatoes.com' + critic.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critics = pd.DataFrame(all_critics)\n",
    "df_critics['critic_id'] = df_critics.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic_name</th>\n",
       "      <th>critic_URL</th>\n",
       "      <th>critic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josefine A.</td>\n",
       "      <td>https://www.rottentomatoes.com/critic/josefine-a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lysalex Hernández A.</td>\n",
       "      <td>https://www.rottentomatoes.com/critic/lysalex-...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arun A.K</td>\n",
       "      <td>https://www.rottentomatoes.com/critic/arun-ak</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex Abad-Santos</td>\n",
       "      <td>https://www.rottentomatoes.com/critic/alex-aba...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Davide Abbatescianni</td>\n",
       "      <td>https://www.rottentomatoes.com/critic/davide-a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            critic_name                                         critic_URL  \\\n",
       "0           Josefine A.   https://www.rottentomatoes.com/critic/josefine-a   \n",
       "1  Lysalex Hernández A.  https://www.rottentomatoes.com/critic/lysalex-...   \n",
       "2              Arun A.K      https://www.rottentomatoes.com/critic/arun-ak   \n",
       "3      Alex Abad-Santos  https://www.rottentomatoes.com/critic/alex-aba...   \n",
       "4  Davide Abbatescianni  https://www.rottentomatoes.com/critic/davide-a...   \n",
       "\n",
       "   critic_id  \n",
       "0          1  \n",
       "1          2  \n",
       "2          3  \n",
       "3          4  \n",
       "4          5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_critics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3576, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_critics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export of all the critics name, URL and id.\n",
    "df_critics.to_csv('data/scrapped_data/all_critics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to start from here with the csv 'all_critics'\n",
    "df_critics = pd.read_csv('data/scrapped_data/all_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we scrap the all the rates given by each reviewer\n",
    "\n",
    "all_scores= {\n",
    "            'critic_id' : [],\n",
    "            'scrapping_status' : [],\n",
    "            'critic_score': [],\n",
    "            'critic_bool' : [],\n",
    "            'RT_score': [],\n",
    "            'movie_URL': [],\n",
    "            'movie_title': [],\n",
    "            'movie_year': []\n",
    "            }\n",
    "\n",
    "all_scores_pd = pd.DataFrame(all_scores)\n",
    "all_scores_pd.to_csv('data_collected/all_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.rottentomatoes.com/critic/josefine-a/movies?page=1\n"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
    "critic_processed = 0\n",
    "\n",
    "for j in range(df_critics['critic_id'].max()):\n",
    "    i = 1\n",
    "    critic_id = j + 1\n",
    "    critic_URL = df_critics.iloc[j,1]\n",
    "    \n",
    "    # we try that because not all critics have a 'movie' URL (only 'TV' for example) and because we don't know how many critics\n",
    "    # have been written by this individual.\n",
    "    movie_score_URL = critic_URL + '/movies?page=' + str(i)\n",
    "    print(movie_score_URL)\n",
    "    r = requests.get(movie_score_URL, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    if r.url[-2:] == 'tv' or soup.select(\"#review-table-body tr\") == []:\n",
    "        print('problem while attempting to scrap :', movie_score_URL)\n",
    "        all_scores['critic_id'].append(critic_id)\n",
    "        all_scores['scrapping_status'].append('nothing_found')\n",
    "        all_scores['critic_score'].append(None)\n",
    "        all_scores['RT_score'].append(None)\n",
    "        all_scores['movie_URL'].append(None)\n",
    "        all_scores['movie_title'].append(None)\n",
    "        all_scores['movie_year'].append(None)\n",
    "    else:\n",
    "        scrap_status = True\n",
    "        while scrap_status == True:\n",
    "            soup = BeautifulSoup(r.content, 'html.parser')\n",
    "            for movie in soup.select(\"#review-table-body tr\"):\n",
    "                try:\n",
    "                    movie_data = movie.find_all('td')\n",
    "                    all_scores['critic_id'].append(critic_id)\n",
    "                    all_scores['scrapping_status'].append('ok') # means at_least_one_review_found\n",
    "                    all_scores['critic_score'].append(movie_data[0].get_text().strip())\n",
    "\n",
    "                    critic_logo = movie_data[0].find('span').get_attribute_list('class')[2]\n",
    "                    if critic_logo == 'fresh':\n",
    "                        all_scores['critic_bool'].append(1)\n",
    "                    elif critic_logo == 'rotten':\n",
    "                        all_scores['critic_bool'].append(0)\n",
    "                    else:\n",
    "                        all_scores['critic_bool'].append(None)\n",
    "\n",
    "                    all_scores['RT_score'].append(movie_data[1].get_text().strip())\n",
    "                    all_scores['movie_URL'].append(movie_data[2].find('a').get('href'))\n",
    "                    movie_desc = movie_data[2].get_text().strip().replace('\\n', '')\n",
    "                    year = movie_desc[-5:-1]\n",
    "                    title = movie_desc.replace('(' + year + ')', '')\n",
    "                    all_scores['movie_year'].append(year)\n",
    "                    all_scores['movie_title'].append(' '.join(title.split()))\n",
    "                except:\n",
    "                    pass\n",
    "            # we move to the next page\n",
    "            i +=1\n",
    "            print(i)\n",
    "            movie_score_URL = critic_URL + '/movies?page=' + str(i)\n",
    "            print(movie_score_URL)\n",
    "            r = requests.get(movie_score_URL, headers=headers)\n",
    "            soup = BeautifulSoup(r.content, 'html.parser')\n",
    "            if soup.select(\"#review-table-body tr\")==[]:\n",
    "                scrap_status = False\n",
    "                critic_processed += 1\n",
    "                if critic_processed % 10 == 1:\n",
    "                    print(all_scores)\n",
    "                    all_scores_pd = pd.DataFrame(all_scores)\n",
    "                    all_scores_pd.to_csv('data_collected/all_scores.csv', index=False, mode='a', header=False)                 \n",
    "                    all_scores= {'critic_id' : [],'scrapping_status' : [],'critic_score': [],'critic_bool' : [],\n",
    "                                 'RT_score': [],#'RT_bool' : [],\n",
    "                                 'movie_URL': [], 'movie_title': [], 'movie_year': []\n",
    "                                }\n",
    "                print('end of this critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurerhugo/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_all_scores = pd.read_csv('data/scrapped_data/all_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(871304, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we collected 871,304 reviews that can be used to build a collaborative filtering model (user/item rates matrix)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
