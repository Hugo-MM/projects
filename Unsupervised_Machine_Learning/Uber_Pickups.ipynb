{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of Uber Pickups project\n",
    "\n",
    "#### 1. Characterize a business need\n",
    "#### 2. Install useful librairies, retrieve data and process it accordingly to our objective\n",
    "#### 3. Implement a solution with DBScan\n",
    "#### 4. Try another solution with K-Means\n",
    "#### 5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The objective is to create algorithms for Uber that will determine where are the hot-zones that drivers should be in. At least two requirements are identified to achieve this goal:\n",
    "- create an algorithm to fin hot zones\n",
    "- visualize results on a dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have at our disposal exhaustive data from Uber for the months of April, May, June, July, August and September 2014. The data contains every Uber ride which took place in New York City and provide the following information :\n",
    "- data and hour of the ride\n",
    "- latitude and longitude\n",
    "- corresponding taxi zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We chose here to focus on working hours (8 am - 20 pm from Monday to Friday) for the Q2-2014 but the code can be easily adapted to any other time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr = pd.read_csv('data/uber-raw-data-apr14.csv').drop('Base',axis=1)\n",
    "may = pd.read_csv('data/uber-raw-data-may14.csv').drop('Base',axis=1)\n",
    "jun = pd.read_csv('data/uber-raw-data-jun14.csv').drop('Base',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the month of Q2-2014, we have 1,880,795 rides.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/1/2014 0:11:00</td>\n",
       "      <td>40.7690</td>\n",
       "      <td>-73.9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/1/2014 0:17:00</td>\n",
       "      <td>40.7267</td>\n",
       "      <td>-74.0345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/1/2014 0:21:00</td>\n",
       "      <td>40.7316</td>\n",
       "      <td>-73.9873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2014 0:28:00</td>\n",
       "      <td>40.7588</td>\n",
       "      <td>-73.9776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/1/2014 0:33:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date/Time      Lat      Lon\n",
       "0  4/1/2014 0:11:00  40.7690 -73.9549\n",
       "1  4/1/2014 0:17:00  40.7267 -74.0345\n",
       "2  4/1/2014 0:21:00  40.7316 -73.9873\n",
       "3  4/1/2014 0:28:00  40.7588 -73.9776\n",
       "4  4/1/2014 0:33:00  40.7594 -73.9722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1880790</th>\n",
       "      <td>6/30/2014 22:40:00</td>\n",
       "      <td>40.7332</td>\n",
       "      <td>-73.9872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880791</th>\n",
       "      <td>6/30/2014 23:12:00</td>\n",
       "      <td>40.7905</td>\n",
       "      <td>-73.9796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880792</th>\n",
       "      <td>6/30/2014 23:13:00</td>\n",
       "      <td>40.7640</td>\n",
       "      <td>-73.9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880793</th>\n",
       "      <td>6/30/2014 23:15:00</td>\n",
       "      <td>40.7262</td>\n",
       "      <td>-73.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880794</th>\n",
       "      <td>6/30/2014 23:35:00</td>\n",
       "      <td>40.7404</td>\n",
       "      <td>-73.9848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date/Time      Lat      Lon\n",
       "1880790  6/30/2014 22:40:00  40.7332 -73.9872\n",
       "1880791  6/30/2014 23:12:00  40.7905 -73.9796\n",
       "1880792  6/30/2014 23:13:00  40.7640 -73.9887\n",
       "1880793  6/30/2014 23:15:00  40.7262 -73.9944\n",
       "1880794  6/30/2014 23:35:00  40.7404 -73.9848"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.concat([apr, may, jun]).reset_index(drop=True)\n",
    "print('For the month of Q2-2014, we have {:,} rides.'.format(data.shape[0]))\n",
    "display(data.head())\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We process the data in order to keep only working hours (8am-20pm from Monday to Friday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We process the data in order to keep only working hours (8am-20pm from Monday to Friday)\n",
    "data['date'] = pd.to_datetime(data['Date/Time'])\n",
    "data = data.drop('Date/Time',axis=1)\n",
    "data['hour'] = data['date'].apply(lambda x : x.hour)\n",
    "data['week_day'] = data['date'].apply(lambda x : x.weekday()) # the day of the week with Monday=0, Sunday=6.\n",
    "data['month'] = data['date'].apply(lambda x : x.month)\n",
    "data = data.drop('date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>hour</th>\n",
       "      <th>week_day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.7690</td>\n",
       "      <td>-73.9549</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.7267</td>\n",
       "      <td>-74.0345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.7316</td>\n",
       "      <td>-73.9873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.7588</td>\n",
       "      <td>-73.9776</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lat      Lon  hour  week_day  month\n",
       "0  40.7690 -73.9549     0         1      4\n",
       "1  40.7267 -74.0345     0         1      4\n",
       "2  40.7316 -73.9873     0         1      4\n",
       "3  40.7588 -73.9776     0         1      4\n",
       "4  40.7594 -73.9722     0         1      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement a solution with DBScan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBScan seems adapted to our business need since it is based on the calculation of density which can be interpreted here as the number of rides observed in a given range. By selecting the highest density clusters, we can identify where the 'hot spots' are and recommend to Uber drivers to reach these areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The quality of the recommendation is directly linked to the density of the clusters which can be determined as follows thanks to the 'epsilon' and 'min_sample' parameters of DBScan:\n",
    "- low epsilon and high min_sample : high denstity\n",
    "- high epsilon and low min_sample : low denstity\n",
    "- low epsilon and low min_sample : high sensitivity to outliers\n",
    "- high epsilon and high min_sample : low sensitivity to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this project, we decide to identify clusters with at least 100 rides that are located only within a 200 meters distance with each other. Various values have been tried, this combinaison appears to be relevant regarding the business objectives (a Uber user should wait more than 5-7 minutes) and the spatial repartition of the clusters identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another advantage of DBScan is that many metrics have been implemented into the sk-learn model. Since the rides are directly identified with GPS coordinates, we will use the haversine distance which computes distance between two points at the surface of the globe based on earth radius and GPS coordinates (expressed in radians, so we will need to copnvert the original data which is in degrees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "earth_radius_km = (6378.137 + 6356.752) / 2 # average earth radius between equatorial and polar radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of parameters : epsilon and min_samples\n",
    "epsilon = 0.2 / earth_radius_km\n",
    "min_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of variables that will contain the relevant information for the clusters.\n",
    "results = pd.DataFrame(columns = ['Lat','Lon','week_day','hour','cluster'])\n",
    "center_points_dict = {'week_day':[], 'hour':[], 'cluster':[], 'lat':[], 'lon':[], 'rides':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traitement du jour 0 et de de l'heure 8.\n",
      "traitement du jour 0 et de de l'heure 9.\n",
      "traitement du jour 0 et de de l'heure 10.\n",
      "traitement du jour 0 et de de l'heure 11.\n",
      "traitement du jour 0 et de de l'heure 12.\n",
      "traitement du jour 0 et de de l'heure 13.\n",
      "traitement du jour 0 et de de l'heure 14.\n",
      "traitement du jour 0 et de de l'heure 15.\n",
      "traitement du jour 0 et de de l'heure 16.\n",
      "traitement du jour 0 et de de l'heure 17.\n",
      "traitement du jour 0 et de de l'heure 18.\n",
      "traitement du jour 0 et de de l'heure 19.\n",
      "traitement du jour 0 et de de l'heure 20.\n",
      "traitement du jour 1 et de de l'heure 8.\n",
      "traitement du jour 1 et de de l'heure 9.\n",
      "traitement du jour 1 et de de l'heure 10.\n",
      "traitement du jour 1 et de de l'heure 11.\n",
      "traitement du jour 1 et de de l'heure 12.\n",
      "traitement du jour 1 et de de l'heure 13.\n",
      "traitement du jour 1 et de de l'heure 14.\n",
      "traitement du jour 1 et de de l'heure 15.\n",
      "traitement du jour 1 et de de l'heure 16.\n",
      "traitement du jour 1 et de de l'heure 17.\n",
      "traitement du jour 1 et de de l'heure 18.\n",
      "traitement du jour 1 et de de l'heure 19.\n",
      "traitement du jour 1 et de de l'heure 20.\n",
      "traitement du jour 2 et de de l'heure 8.\n",
      "traitement du jour 2 et de de l'heure 9.\n",
      "traitement du jour 2 et de de l'heure 10.\n",
      "traitement du jour 2 et de de l'heure 11.\n",
      "traitement du jour 2 et de de l'heure 12.\n",
      "traitement du jour 2 et de de l'heure 13.\n",
      "traitement du jour 2 et de de l'heure 14.\n",
      "traitement du jour 2 et de de l'heure 15.\n",
      "traitement du jour 2 et de de l'heure 16.\n",
      "traitement du jour 2 et de de l'heure 17.\n",
      "traitement du jour 2 et de de l'heure 18.\n",
      "traitement du jour 2 et de de l'heure 19.\n",
      "traitement du jour 2 et de de l'heure 20.\n",
      "traitement du jour 3 et de de l'heure 8.\n",
      "traitement du jour 3 et de de l'heure 9.\n",
      "traitement du jour 3 et de de l'heure 10.\n",
      "traitement du jour 3 et de de l'heure 11.\n",
      "traitement du jour 3 et de de l'heure 12.\n",
      "traitement du jour 3 et de de l'heure 13.\n",
      "traitement du jour 3 et de de l'heure 14.\n",
      "traitement du jour 3 et de de l'heure 15.\n",
      "traitement du jour 3 et de de l'heure 16.\n",
      "traitement du jour 3 et de de l'heure 17.\n",
      "traitement du jour 3 et de de l'heure 18.\n",
      "traitement du jour 3 et de de l'heure 19.\n",
      "traitement du jour 3 et de de l'heure 20.\n",
      "traitement du jour 4 et de de l'heure 8.\n",
      "traitement du jour 4 et de de l'heure 9.\n",
      "traitement du jour 4 et de de l'heure 10.\n",
      "traitement du jour 4 et de de l'heure 11.\n",
      "traitement du jour 4 et de de l'heure 12.\n",
      "traitement du jour 4 et de de l'heure 13.\n",
      "traitement du jour 4 et de de l'heure 14.\n",
      "traitement du jour 4 et de de l'heure 15.\n",
      "traitement du jour 4 et de de l'heure 16.\n",
      "traitement du jour 4 et de de l'heure 17.\n",
      "traitement du jour 4 et de de l'heure 18.\n",
      "traitement du jour 4 et de de l'heure 19.\n",
      "traitement du jour 4 et de de l'heure 20.\n",
      "CPU times: user 4min 2s, sys: 342 ms, total: 4min 2s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for week_day in range(5):\n",
    "    for hour in range(8,21):\n",
    "        print('traitement du jour {:d} et de de l\\'heure {:d}.'.format(week_day, hour))\n",
    "        \n",
    "        # Selection of relevant data        \n",
    "        data_temp = data.loc[(data['hour'] == hour) & (data['week_day'] == week_day)].drop(['hour', 'week_day','month'], axis=1)\n",
    "        coords = np.radians(data_temp) # it's necessary to convert the GPS coordinates into radians\n",
    "        \n",
    "        # Fitting of the DBScan\n",
    "        db = DBSCAN(eps=epsilon, min_samples=100, metric='haversine', algorithm='auto') # use of haversine distance\n",
    "        db.fit(coords)\n",
    "        \n",
    "        # Record of the results : we retrieve the clusters identified thanks to 'db.labels_'\n",
    "        coords[['Lat','Lon']] = np.degrees(coords[['Lat','Lon']])\n",
    "        coords['cluster'] = db.labels_\n",
    "        coords['week_day'] = week_day\n",
    "        coords['hour'] = hour\n",
    "        results = pd.concat([results,coords])\n",
    "        \n",
    "        # Calculation of the center of each cluster, we first remove the outliers (or noise) rides identified with '-1' in db.labels_\n",
    "        cluster_list = list(coords['cluster'].unique())\n",
    "        cluster_list.remove(-1)\n",
    "        for i in cluster_list:\n",
    "            data_temp_center = coords.loc[coords['cluster'] == i].drop(['cluster','week_day','hour'],axis=1)\n",
    "            center_points_dict['cluster'].append(i)\n",
    "            center_points_dict['rides'].append(data_temp_center.shape[0])\n",
    "            center_points_dict['lat'].append(np.mean(data_temp_center.Lat))\n",
    "            center_points_dict['lon'].append(np.mean(data_temp_center.Lon))\n",
    "            center_points_dict['hour'].append(hour)\n",
    "            center_points_dict['week_day'].append(week_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to plot the results in a time-animated map, we need to add a proper defined 'time' variable to our 2 dataframes containing the clusters and the centers\n",
    "# of the clusters.\n",
    "days_correspondance = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday'}\n",
    "results['time'] = results['week_day'].replace(days_correspondance) + ', hour : ' + results['hour'].astype(str)\n",
    "center_points_pd = pd.DataFrame(center_points_dict)\n",
    "center_points_pd['time'] = center_points_pd['week_day'].replace(days_correspondance) + ', hour : ' + center_points_pd['hour'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To show the results, we plot the clusters identified on average for every working hour during Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_clusters = px.scatter_mapbox(\n",
    "        results[results.cluster != -1], \n",
    "        lat=\"Lat\", \n",
    "        lon=\"Lon\",\n",
    "        color=\"cluster\",\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        animation_frame = 'time'\n",
    ")\n",
    "\n",
    "fig_clusters.show(\"iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To bring more accurate business information, we can plot the center of the clusters identified. After another processing of the restuls, the size of the marker is determined by the relative number of rides contained in the cluster compared to the other cluster : the bigger marker, the 'hotter' the spot for a Uber rider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>total_rides_per_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Friday, hour : 10</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Friday, hour : 11</td>\n",
       "      <td>2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friday, hour : 12</td>\n",
       "      <td>3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday, hour : 13</td>\n",
       "      <td>5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday, hour : 14</td>\n",
       "      <td>8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Wednesday, hour : 18</td>\n",
       "      <td>16713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Wednesday, hour : 19</td>\n",
       "      <td>13668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Wednesday, hour : 20</td>\n",
       "      <td>14378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Wednesday, hour : 8</td>\n",
       "      <td>3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Wednesday, hour : 9</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  total_rides_per_hour\n",
       "0      Friday, hour : 10                  1135\n",
       "1      Friday, hour : 11                  2042\n",
       "2      Friday, hour : 12                  3064\n",
       "3      Friday, hour : 13                  5252\n",
       "4      Friday, hour : 14                  8297\n",
       "..                   ...                   ...\n",
       "60  Wednesday, hour : 18                 16713\n",
       "61  Wednesday, hour : 19                 13668\n",
       "62  Wednesday, hour : 20                 14378\n",
       "63   Wednesday, hour : 8                  3534\n",
       "64   Wednesday, hour : 9                   882\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides_per_hour = center_points_pd.groupby('time')['rides'].sum().reset_index().rename(columns={'rides':'total_rides_per_hour'})\n",
    "rides_per_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_points = pd.merge(center_points_pd, rides_per_hour, on='time', how='left')\n",
    "center_points['rides_indicator'] = center_points['rides'] / center_points['total_rides_per_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_22.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_centers = px.scatter_mapbox(\n",
    "        center_points, \n",
    "        lat='lat', \n",
    "        lon='lon',\n",
    "        color='cluster',\n",
    "        size = 'rides_indicator',\n",
    "        mapbox_style='carto-positron',\n",
    "        animation_frame = 'time'\n",
    ")\n",
    "\n",
    "fig_centers.show(\"iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The purpose of this section is to try to find clusters thanks to K-Means for a specific hour. The results with DBScan will be compared and discussed in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first step for K-Means is to determined the most suitable number of clusters ('K') thanks to :\n",
    "- the 'elbow' method : computation of the inertia for various values of K\n",
    "- the computation of the 'silhouette' for each K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use the first hour identified in our dataset : hour 8 for Monday during Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.loc[(data['hour'] == 8) & (data['week_day'] == 0)].drop(['hour', 'week_day','month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** results for K = 2. ****\n",
      "Inertia : 30.0\n",
      "Silhouette score : 0.6593\n",
      "\n",
      "**** results for K = 3. ****\n",
      "Inertia : 21.8\n",
      "Silhouette score : 0.4136\n",
      "\n",
      "**** results for K = 4. ****\n",
      "Inertia : 15.8\n",
      "Silhouette score : 0.4464\n",
      "\n",
      "**** results for K = 5. ****\n",
      "Inertia : 12.2\n",
      "Silhouette score : 0.4590\n",
      "\n",
      "**** results for K = 6. ****\n",
      "Inertia : 9.3\n",
      "Silhouette score : 0.4868\n",
      "\n",
      "**** results for K = 7. ****\n",
      "Inertia : 8.3\n",
      "Silhouette score : 0.4922\n",
      "\n",
      "**** results for K = 8. ****\n",
      "Inertia : 7.3\n",
      "Silhouette score : 0.4073\n",
      "\n",
      "**** results for K = 9. ****\n",
      "Inertia : 6.4\n",
      "Silhouette score : 0.4167\n",
      "\n",
      "**** results for K = 10. ****\n",
      "Inertia : 5.7\n",
      "Silhouette score : 0.4334\n"
     ]
    }
   ],
   "source": [
    "# We collect the inertia (sum of of squared distances of each observation to its closest cluster center) and the mean silhouette score for each value of K.\n",
    "# We start at k=2 because this score cannot by definition be computed for less than 2 clusters\n",
    "# (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)\n",
    "\n",
    "all_k = [i for i in range(2,11)]\n",
    "inertia = []\n",
    "silhouette = []\n",
    "for k in all_k: \n",
    "    kmeans = KMeans(n_clusters= k, init = \"k-means++\", random_state = 0)\n",
    "    kmeans.fit(sample_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette.append(silhouette_score(sample_data, kmeans.predict(sample_data)))\n",
    "    print(\"\\n**** results for K = {:d}. ****\".format(k))\n",
    "    print(\"Inertia : {:.1f}\".format(inertia[-1]))\n",
    "    print(\"Silhouette score : {:.4f}\".format(silhouette[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_57.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(pd.DataFrame([inertia, all_k]).T.rename(columns={0:'inertia', 1:'K'}),\n",
    "              x=\"K\",\n",
    "              y=\"inertia\",\n",
    "              title='Elbow method : inertia per number of clusters (K)')\n",
    "fig.show(\"iframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_58.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(pd.DataFrame([silhouette, all_k]).T.rename(columns={0:'silhouette', 1:'K'}),\n",
    "              x=\"K\",\n",
    "              y=\"silhouette\",\n",
    "              title='silhouette per number of clusters (K)')\n",
    "fig.show(\"iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering the shape of the inertia curve, we decide to use K=6 (the steepest change of slope). K=6 seems also consistent regarding the silhouette score as the value is almost the maximum, if we exclude K=2 which doesn't seem to be a good candidate regarding inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 6, init = \"k-means++\", random_state = 0)\n",
    "kmeans.fit(sample_data)\n",
    "sample_data['cluster'] = kmeans.fit_predict(sample_data)\n",
    "sample_data['type'] = 'K-Means'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the results obtained with DBScan and K-means (K=6) for Monday, hour 8 during Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_results = results.loc[(results['hour'] == 8) & (results['week_day'] == 0) & (results['cluster'] != -1)].drop(['hour', 'week_day','time'], axis=1)\n",
    "dbscan_results['type'] = 'DBSCAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussion_df = pd.concat([sample_data, dbscan_results]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_117.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_clusters = px.scatter_mapbox(\n",
    "        discussion_df, \n",
    "        lat=\"Lat\", \n",
    "        lon=\"Lon\",\n",
    "        color=\"cluster\",\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        animation_frame = 'type'\n",
    ")\n",
    "\n",
    "fig_clusters.show(\"iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a conclusion, we would recommend to use DBSCAN over K-Means for this business case beacuse of the following reasons :\n",
    "- K-means is more sensitive to outliers, which is an important issue here : we certainly do not want to recommand to a driver to go into a cluster with a density that would be actually too low. On the contrary, DBSCAN is non-sensitive to outliers (they are actually identified as such).\n",
    "- K-means need to determine the adequate number of clusters for each dataset. It would be complicated to generate the methods used above to determine K=6. On the contrary, DBSCAN determines itself the number of clusters according to the density parameters we chose.£\n",
    "- The most tricky part with DBSCAN is the tuning of epsilon and min_samples parameters but it makes also it very suitable for our business need : we are able to exploit this algorithm with very concrete parameters : max distance between rides to be picked-up and minimum number of rides within an area. As a perspective, we could consider computing the silhouette score for the clusters identified with DBSCAN in order to fine tuned these two parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
